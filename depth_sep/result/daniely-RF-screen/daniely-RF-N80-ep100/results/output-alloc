[[['log(rate)\\log(Gamma)', -4.0, -3.5, -3.0, -2.5, -2.0, -1.5, -1.0, -0.5], [-4.0, 0.8685392297166415, 0.7794381996653004, 0.6381890817932742, 0.6285363431849901, 0.5552883036606622, 0.5895669243980416, 0.7243067439324693, 0.5992463846323568], [-3.5, 0.8220272576119068, 0.5654633233711268, 0.5403550857719303, 0.5407628940137275, 0.507192524431912, 0.5283005117708841, 0.5128154325212928, 0.5082764374689992], [-3.0, 0.6801544346763059, 0.5035335008389117, 0.4979407168361911, 0.5184018271867717, 0.49616778346536405, 0.517834329396072, 0.5023303568724601, 0.49889089840698186], [-2.5, 0.5321691963163306, 0.49825013339414326, 0.49387966902057434, 0.5125502516846123, 0.49425166143304433, 0.5155769902445692, 0.5000099625181569, 0.4989807292300259], [-2.0, 0.4982581158069781, 0.5077807535020484, 0.4990758266266935, 0.5099817224485269, 0.4958752956201377, 0.5160671258126972, 0.5006277888017293, 0.5001624001082448], [-1.5, 0.4966289896097749, 0.49373023674454247, 0.49532105924619696, 0.5099224574183361, 0.5079854222965823, 0.5178297730481635, 0.5029346572788304, 0.5018325036752127], [-1.0, 0.5276070497908988, 0.5003477001978571, 0.5038626297607246, 0.5330779178443048, 0.5173379129997531, 0.5321742470326231, 0.5285341800811856, 0.5043676580273366], [-0.5, 0.7785228859071986, 0.5266955435912675, 0.6065681366202583, 0.5185290205392376, 0.5035226712167162, 0.5454317324189251, 0.558529298159252, 0.5171263909223976]], {'N': 80, 'dataset': 'daniely', 'val_size': 20000, 'classes': [-1.0, 0.0, 1.0], 'bd': 100000, 'feature': 'ReLU', 'task': 'regression', 'model': 'RF', 'logGamma': array([-4. , -3.5, -3. , -2.5, -2. , -1.5, -1. , -0.5]), 'mode': 'layer 2', 'loss_fn': 'squared', 'H': 2, 'lograte': array([-4. , -3.5, -3. , -2.5, -2. , -1.5, -1. , -0.5]), 'folds': 5, 'trials': 10, 'gpu': 0, 'n_epoch': 100}]