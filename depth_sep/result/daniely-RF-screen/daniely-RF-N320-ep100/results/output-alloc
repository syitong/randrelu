[[['log(rate)\\log(Gamma)', -4.0, -3.5, -3.0, -2.5, -2.0, -1.5, -1.0, -0.5], [-4.0, 0.8455635877897182, 0.8805598099959895, 0.9065695482520394, 0.5672962227992951, 0.548394035460006, 0.5399924332710286, 0.5703718997193729, 0.5685386330926454], [-3.5, 0.6586891092841957, 0.5966861215933141, 0.532380312632048, 0.5254389518172089, 0.5254514393170798, 0.5235277432205313, 0.5301191022152778, 0.5389227338958561], [-3.0, 0.504686914816936, 0.5127441999099096, 0.509212585597131, 0.5188253682582865, 0.5160248835042396, 0.5125393649346356, 0.5103601924450537, 0.5168919260565648], [-2.5, 0.5197324427776036, 0.50820993946002, 0.5076205634353255, 0.5215740074915395, 0.5135144953074101, 0.5092852121740217, 0.5075124837583139, 0.5113684167605504], [-2.0, 0.5720950237896062, 0.5425906802123509, 0.5282262755820855, 0.5168925060326006, 0.5139747419636433, 0.5103108150430198, 0.5091640621289492, 0.5124445647204352], [-1.5, 0.49683539493591444, 0.5315883076297448, 0.5126625665365213, 0.5279705182439924, 0.5242001701640656, 0.5146462904193173, 0.5129808000533084, 0.525022315463023], [-1.0, 0.6419777811149301, 0.6057884236711171, 0.513236173810068, 0.7057553449422722, 0.5770427693386965, 0.526662600022747, 0.5491616873586675, 0.54494115329644], [-0.5, 1.1274161077525775, 0.5300401227486884, 0.7561687055602286, 0.6265646634711163, 0.70530676690173, 0.6328438217992348, 0.534304745888417, 0.5872071849194885]], {'classes': [-1.0, 0.0, 1.0], 'lograte': array([-4. , -3.5, -3. , -2.5, -2. , -1.5, -1. , -0.5]), 'H': 2, 'dataset': 'daniely', 'bd': 100000, 'feature': 'ReLU', 'loss_fn': 'squared', 'model': 'RF', 'task': 'regression', 'gpu': 0, 'N': 320, 'val_size': 20000, 'logGamma': array([-4. , -3.5, -3. , -2.5, -2. , -1.5, -1. , -0.5]), 'mode': 'layer 2', 'n_epoch': 100, 'folds': 5, 'trials': 10}]