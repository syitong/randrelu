[[['log(rate)\\log(Gamma)', -4.0, -2.0, 0.0], [-4.0, 0.46075, 0.455, 0.457], [-3.5, 0.46075, 0.455, 0.457], [-3.0, 0.46075, 0.434, 0.4525], [-2.5, 0.4075, 0.442, 0.4285], [-2.0, 0.46075, 0.42125, 0.512], [-1.5, 0.4075, 0.54025, 0.49225], [-1.0, 0.4075, 0.40575, 0.481], [-0.5, 0.4075, 0.40125, 0.4525]], {'feature': 'ReLU', 'n_epoch': 10, 'classes': [-1.0, 0.0, 1.0], 'mode': 'layer 2', 'dataset': 'eldan', 'trials': 8, 'bd': 100000, 'N': 1280, 'logGamma': array([-4., -2.,  0.]), 'val_size': 20000, 'task': 'classification', 'gpu': 0, 'lograte': array([-4. , -3.5, -3. , -2.5, -2. , -1.5, -1. , -0.5]), 'model': 'RF', 'folds': 5, 'loss_fn': 'log'}]